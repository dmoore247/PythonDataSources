{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c0d0364-c6b3-4b1b-82d6-9b1551d9bee9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install pydicom==3.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd595989-e942-4dae-94e7-66c511065188",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(\"zipdcm\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(filename)s:%(lineno)s - %(levelname)s - %(message)s')\n",
    "# Create a handler (e.g., StreamHandler for console output)\n",
    "handler = logging.StreamHandler()\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "# Add the handler to the logger\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "407b2ea1-6eaa-4447-aac2-1f9e6b442c57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.datasource import DataSource, DataSourceReader\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType\n",
    "from zip_dcm_ds import ZipDCMDataSource\n",
    "\n",
    "def test_single(spark):\n",
    "    # test a single zip (with a dcm and a license file)\n",
    "    df = (\n",
    "        spark.read\n",
    "            .option('numPartitions','1')\n",
    "            .format(\"zipdcm\")\n",
    "            .load(\"./resources/dcms/3.5.574.1.3.9030958.6.376.2860280475000825621.zip\")\n",
    "    )\n",
    "    result = df.collect()\n",
    "    assert len(result) == 1\n",
    "    print(result)\n",
    "\n",
    "def test_folder(spark):\n",
    "    # test on a folder of zips\n",
    "    df = (\n",
    "        spark.read\n",
    "          .option('numPartitions','2')\n",
    "          .format(\"zipdcm\")\n",
    "          .load(\"./resources/dcms\")\n",
    "    )\n",
    "    df.write.format('delta').mode('overwrite').saveAsTable(\"douglas_moore.pixels.zipdcm_test\")\n",
    "\n",
    "def test_scale(spark, numPartitions=128):\n",
    "    df = (\n",
    "        spark.read\n",
    "          .option('numPartitions',f'{numPartitions}')\n",
    "          .format(\"zipdcm\")\n",
    "          .load(\"/Volumes/hls_radiology/tcia/downloads/tciaDownload\")\n",
    "    )\n",
    "    df.write.format('delta').mode('overwrite').saveAsTable(\"douglas_moore.pixels.zipdcm_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8be72cd3-3d72-4c18-983b-4782d80dd262",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# how many zips do we have?\n",
    "df = (\n",
    "    spark.read.format(\"binaryFile\")\n",
    "        .option(\"pathGlobFilter\", \"*.zip\")\n",
    "        .option(\"recursiveFileLookup\", \"true\")\n",
    "        .load(\"/Volumes/hls_radiology/tcia/downloads/tciaDownload\").drop('content')\n",
    "    )\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1777971-498d-4e9f-bb0b-79e8db236241",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "total_worker_cores = 32\n",
    "\n",
    "# Add our custom Python DataSource for DICMO files storaged in a Zip Archive\n",
    "spark.dataSource.register(ZipDCMDataSource)\n",
    "\n",
    "#test_single(spark)\n",
    "#test_folder(spark)\n",
    "test_scale(spark, 128)\n",
    "\n",
    "end_time = time.time()\n",
    "operation_time = end_time - start_time\n",
    "logger.info(f\"Operation time: {operation_time} seconds and {operation_time * total_worker_cores} core-seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4869d7d-5534-421b-88b8-1f21594992a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "total_worker_cores = 32\n",
    "\n",
    "# Add our custom Python DataSource for DICMO files storaged in a Zip Archive\n",
    "spark.dataSource.register(ZipDCMDataSource)\n",
    "\n",
    "#test_single(spark)\n",
    "#test_folder(spark)\n",
    "test_scale(spark, 64)\n",
    "\n",
    "end_time = time.time()\n",
    "operation_time = end_time - start_time\n",
    "logger.info(f\"Operation time: {operation_time} seconds and {operation_time * total_worker_cores} core-seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44effaf2-a762-474b-9f9a-d95bef2df41d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Summary stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55067a71-2848-4cc5-b414-78d4c3394c37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select count(distinct zipfile) zipfiles, count(distinct zipfile, dcmfile) dcmfiles, count(distinct rowid), count(1) records\n",
    "from douglas_moore.pixels.zipdcm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0588c3a-8ef1-479c-a7b7-8861787135ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * \n",
    "from douglas_moore.pixels.zipdcm_test\n",
    "limit 100;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2588019255029477,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Python DataSources - Cracking Zip files",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
